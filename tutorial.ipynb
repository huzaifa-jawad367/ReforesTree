{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ReforesTree 🌴\n",
    "\n",
    "We are excited to share with you the ReforesTree dataset! 🎉\n",
    "We introduce the ReforesTree dataset in hopes of encouraging the fellow machine learning community to take on\n",
    "the challenge of developing low-cost, scalable, trustworthy and accurate solutions for monitoring, verification and reporting of tropical reforestation inventory. \n",
    "\n",
    "#### This is a dataset for the following 6 agroforestry sites\n",
    "In alphabetical order\n",
    "1. _Carlos Vera Arteaga_\n",
    "2. _Carlos Vera Guevara_\n",
    "3. _Flora Pluas_\n",
    "4. _Leonor Aspiazu_\n",
    "5. _Manuel Macias_\n",
    "6. _Nestor Macias_\n",
    "\n",
    "\n",
    "## Dataset Components\n",
    "For each site the data we publish consists of four components free for use:\n",
    "1. 🛸 Raw drone RGB images _(see wwf_ecuador/\"Name of site\")_\n",
    "2. 🌴 Hand measured tree parameters (diameter at breast height, species, biomass, and location) of every tree _(see field_data.csv)_\n",
    "3. 🔲 Set of bounding boxes of trees for each site cleaned by hand and labeled as banana or not banana _(see annotations/cleaned)_\n",
    "4. ↔️ Mappings of these bounding boxes with tree labels based on location _(see mappings/final)_\n",
    "\n",
    "\n",
    "## Tutorial\n",
    "In this tutorial we go through the steps to recreate (and hopefully improve) the dataset and how to use it. \n",
    "\n",
    "Please read our paper [here](https://arxiv.org/abs/2201.11192).\n",
    "For any questions, please reach out to gyri.reiersen@tum.de or david.dao@inf.eth.ch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load packages and modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: POT in /opt/anaconda3/envs/py37/lib/python3.7/site-packages (from -r requirements.txt (line 1)) (0.8.0)\n",
      "Collecting POT\n",
      "  Using cached POT-0.8.1.0-cp37-cp37m-macosx_10_9_x86_64.whl (189 kB)\n",
      "Requirement already satisfied: Pillow in /opt/anaconda3/envs/py37/lib/python3.7/site-packages (from -r requirements.txt (line 2)) (9.1.0)\n",
      "Requirement already satisfied: pandas>=1.1.3 in /opt/anaconda3/envs/py37/lib/python3.7/site-packages (from -r requirements.txt (line 3)) (1.1.5)\n",
      "Collecting pandas>=1.1.3\n",
      "  Downloading pandas-1.3.5-cp37-cp37m-macosx_10_9_x86_64.whl (11.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 11.0 MB 5.5 MB/s eta 0:00:01    |████████████████████▎           | 7.0 MB 5.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.19.5 in /opt/anaconda3/envs/py37/lib/python3.7/site-packages (from -r requirements.txt (line 4)) (1.20.0)\n",
      "Collecting numpy>=1.19.5\n",
      "  Downloading numpy-1.21.6-cp37-cp37m-macosx_10_9_x86_64.whl (16.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 16.9 MB 24.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: geopandas>=0.8.1 in /opt/anaconda3/envs/py37/lib/python3.7/site-packages (from -r requirements.txt (line 5)) (0.8.2)\n",
      "Collecting geopandas>=0.8.1\n",
      "  Downloading geopandas-0.10.2-py2.py3-none-any.whl (1.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.0 MB 25.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: rasterio>=1.1.8 in /opt/anaconda3/envs/py37/lib/python3.7/site-packages (from -r requirements.txt (line 6)) (1.1.8)\n",
      "Collecting rasterio>=1.1.8\n",
      "  Downloading rasterio-1.2.10-cp37-cp37m-macosx_10_9_x86_64.whl (21.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 21.1 MB 13.2 MB/s eta 0:00:01�█▉         | 15.1 MB 26.5 MB/s eta 0:00:01     |██████████████████████████████  | 19.8 MB 13.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: matplotlib>=3.3.3 in /opt/anaconda3/envs/py37/lib/python3.7/site-packages (from -r requirements.txt (line 7)) (3.3.4)\n",
      "Collecting matplotlib>=3.3.3\n",
      "  Downloading matplotlib-3.5.1-cp37-cp37m-macosx_10_9_x86_64.whl (7.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 7.3 MB 18.4 MB/s eta 0:00:01     |████▌                           | 1.0 MB 18.4 MB/s eta 0:00:01     |██████▎                         | 1.4 MB 18.4 MB/s eta 0:00:01     |███████████████████████         | 5.2 MB 18.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: shapely>=1.7.1 in /opt/anaconda3/envs/py37/lib/python3.7/site-packages (from -r requirements.txt (line 8)) (1.7.1)\n",
      "Collecting shapely>=1.7.1\n",
      "  Downloading Shapely-1.8.1.post1-cp37-cp37m-macosx_10_9_x86_64.whl (1.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.2 MB 5.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: opencv-python in /opt/anaconda3/envs/py37/lib/python3.7/site-packages (from -r requirements.txt (line 9)) (4.5.5.64)\n",
      "Requirement already satisfied: seaborn>=0.11.1 in /opt/anaconda3/envs/py37/lib/python3.7/site-packages (from -r requirements.txt (line 10)) (0.11.2)\n",
      "Requirement already satisfied: scikit-image>=0.17.2 in /opt/anaconda3/envs/py37/lib/python3.7/site-packages (from -r requirements.txt (line 11)) (0.19.2)\n",
      "Requirement already satisfied: pyproj>=2.2 in /opt/anaconda3/envs/py37/lib/python3.7/site-packages (from -r requirements.txt (line 12)) (3.2.1)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/envs/py37/lib/python3.7/site-packages (from -r requirements.txt (line 13)) (62.1.0)\n",
      "Requirement already satisfied: pytorch-lightning>=1.4.4 in /opt/anaconda3/envs/py37/lib/python3.7/site-packages (from -r requirements.txt (line 14)) (1.4.4)\n",
      "Collecting pytorch-lightning>=1.4.4\n",
      "  Downloading pytorch_lightning-1.6.1-py3-none-any.whl (582 kB)\n",
      "\u001b[K     |████████████████████████████████| 582 kB 10.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: torch>=1.9.0 in /opt/anaconda3/envs/py37/lib/python3.7/site-packages (from -r requirements.txt (line 15)) (1.9.0)\n",
      "Collecting torch>=1.9.0\n",
      "  Downloading torch-1.11.0-cp37-none-macosx_10_9_x86_64.whl (129.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 129.9 MB 13 kB/s  eta 0:00:01    |▉                               | 3.2 MB 14.9 MB/s eta 0:00:09     |███▎                            | 13.3 MB 14.9 MB/s eta 0:00:08     |██████                          | 24.8 MB 29.0 MB/s eta 0:00:04     |██████████▋                     | 43.1 MB 667 kB/s eta 0:02:10     |███████████████▎                | 61.9 MB 703 kB/s eta 0:01:37     |████████████████████▊           | 84.2 MB 646 kB/s eta 0:01:11 0:00:23     |████████████████████████████▌   | 115.8 MB 805 kB/s eta 0:00:18     |██████████████████████████████  | 122.1 MB 461 kB/s eta 0:00:17     |██████████████████████████████▉ | 125.3 MB 461 kB/s eta 0:00:10     |███████████████████████████████▌| 127.6 MB 461 kB/s eta 0:00:05\n",
      "\u001b[?25hCollecting tensorboard>=2.6.0\n",
      "  Downloading tensorboard-2.8.0-py3-none-any.whl (5.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.8 MB 20.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: torchvision>=0.10.0 in /opt/anaconda3/envs/py37/lib/python3.7/site-packages (from -r requirements.txt (line 17)) (0.10.0)\n",
      "Collecting torchvision>=0.10.0\n",
      "  Downloading torchvision-0.12.0-cp37-cp37m-macosx_10_9_x86_64.whl (1.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.3 MB 23.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy>=1.0 in /opt/anaconda3/envs/py37/lib/python3.7/site-packages (from POT->-r requirements.txt (line 1)) (1.7.3)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/anaconda3/envs/py37/lib/python3.7/site-packages (from pandas>=1.1.3->-r requirements.txt (line 3)) (2021.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/anaconda3/envs/py37/lib/python3.7/site-packages (from pandas>=1.1.3->-r requirements.txt (line 3)) (2.8.2)\n",
      "Requirement already satisfied: fiona>=1.8 in /opt/anaconda3/envs/py37/lib/python3.7/site-packages (from geopandas>=0.8.1->-r requirements.txt (line 5)) (1.8.20)\n",
      "Requirement already satisfied: affine in /opt/anaconda3/envs/py37/lib/python3.7/site-packages (from rasterio>=1.1.8->-r requirements.txt (line 6)) (2.3.0)\n",
      "Requirement already satisfied: attrs in /opt/anaconda3/envs/py37/lib/python3.7/site-packages (from rasterio>=1.1.8->-r requirements.txt (line 6)) (21.2.0)\n",
      "Requirement already satisfied: click-plugins in /opt/anaconda3/envs/py37/lib/python3.7/site-packages (from rasterio>=1.1.8->-r requirements.txt (line 6)) (1.1.1)\n",
      "Requirement already satisfied: cligj>=0.5 in /opt/anaconda3/envs/py37/lib/python3.7/site-packages (from rasterio>=1.1.8->-r requirements.txt (line 6)) (0.7.2)\n",
      "Requirement already satisfied: click>=4.0 in /opt/anaconda3/envs/py37/lib/python3.7/site-packages (from rasterio>=1.1.8->-r requirements.txt (line 6)) (7.1.2)\n",
      "Requirement already satisfied: snuggs>=1.4.1 in /opt/anaconda3/envs/py37/lib/python3.7/site-packages (from rasterio>=1.1.8->-r requirements.txt (line 6)) (1.4.7)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/envs/py37/lib/python3.7/site-packages (from rasterio>=1.1.8->-r requirements.txt (line 6)) (2021.5.30)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/anaconda3/envs/py37/lib/python3.7/site-packages (from matplotlib>=3.3.3->-r requirements.txt (line 7)) (1.3.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/envs/py37/lib/python3.7/site-packages (from matplotlib>=3.3.3->-r requirements.txt (line 7)) (21.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/anaconda3/envs/py37/lib/python3.7/site-packages (from matplotlib>=3.3.3->-r requirements.txt (line 7)) (2.4.7)\n",
      "Collecting fonttools>=4.22.0\n",
      "  Downloading fonttools-4.32.0-py3-none-any.whl (900 kB)\n",
      "\u001b[K     |████████████████████████████████| 900 kB 29.3 MB/s eta 0:00:01     |███████████████████████████████ | 870 kB 29.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: cycler>=0.10 in /opt/anaconda3/envs/py37/lib/python3.7/site-packages (from matplotlib>=3.3.3->-r requirements.txt (line 7)) (0.10.0)\n",
      "Requirement already satisfied: imageio>=2.4.1 in /opt/anaconda3/envs/py37/lib/python3.7/site-packages (from scikit-image>=0.17.2->-r requirements.txt (line 11)) (2.9.0)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /opt/anaconda3/envs/py37/lib/python3.7/site-packages (from scikit-image>=0.17.2->-r requirements.txt (line 11)) (2021.8.8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyWavelets>=1.1.1 in /opt/anaconda3/envs/py37/lib/python3.7/site-packages (from scikit-image>=0.17.2->-r requirements.txt (line 11)) (1.1.1)\n",
      "Requirement already satisfied: networkx>=2.2 in /opt/anaconda3/envs/py37/lib/python3.7/site-packages (from scikit-image>=0.17.2->-r requirements.txt (line 11)) (2.6.2)\n",
      "Requirement already satisfied: tqdm>=4.41.0 in /opt/anaconda3/envs/py37/lib/python3.7/site-packages (from pytorch-lightning>=1.4.4->-r requirements.txt (line 14)) (4.62.2)\n",
      "Requirement already satisfied: torchmetrics>=0.4.1 in /opt/anaconda3/envs/py37/lib/python3.7/site-packages (from pytorch-lightning>=1.4.4->-r requirements.txt (line 14)) (0.5.0)\n",
      "Collecting typing-extensions>=4.0.0\n",
      "  Downloading typing_extensions-4.1.1-py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: pyDeprecate<0.4.0,>=0.3.1 in /opt/anaconda3/envs/py37/lib/python3.7/site-packages (from pytorch-lightning>=1.4.4->-r requirements.txt (line 14)) (0.3.1)\n",
      "Requirement already satisfied: PyYAML>=5.4 in /opt/anaconda3/envs/py37/lib/python3.7/site-packages (from pytorch-lightning>=1.4.4->-r requirements.txt (line 14)) (6.0)\n",
      "Requirement already satisfied: fsspec[http]!=2021.06.0,>=2021.05.0 in /opt/anaconda3/envs/py37/lib/python3.7/site-packages (from pytorch-lightning>=1.4.4->-r requirements.txt (line 14)) (2021.7.0)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /opt/anaconda3/envs/py37/lib/python3.7/site-packages (from tensorboard>=2.6.0->-r requirements.txt (line 16)) (1.39.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/anaconda3/envs/py37/lib/python3.7/site-packages (from tensorboard>=2.6.0->-r requirements.txt (line 16)) (2.26.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/anaconda3/envs/py37/lib/python3.7/site-packages (from tensorboard>=2.6.0->-r requirements.txt (line 16)) (1.35.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/anaconda3/envs/py37/lib/python3.7/site-packages (from tensorboard>=2.6.0->-r requirements.txt (line 16)) (0.6.1)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /opt/anaconda3/envs/py37/lib/python3.7/site-packages (from tensorboard>=2.6.0->-r requirements.txt (line 16)) (3.17.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/anaconda3/envs/py37/lib/python3.7/site-packages (from tensorboard>=2.6.0->-r requirements.txt (line 16)) (0.4.5)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/anaconda3/envs/py37/lib/python3.7/site-packages (from tensorboard>=2.6.0->-r requirements.txt (line 16)) (3.3.4)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/anaconda3/envs/py37/lib/python3.7/site-packages (from tensorboard>=2.6.0->-r requirements.txt (line 16)) (1.8.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /opt/anaconda3/envs/py37/lib/python3.7/site-packages (from tensorboard>=2.6.0->-r requirements.txt (line 16)) (0.37.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/anaconda3/envs/py37/lib/python3.7/site-packages (from tensorboard>=2.6.0->-r requirements.txt (line 16)) (2.0.1)\n",
      "Requirement already satisfied: absl-py>=0.4 in /opt/anaconda3/envs/py37/lib/python3.7/site-packages (from tensorboard>=2.6.0->-r requirements.txt (line 16)) (0.13.0)\n",
      "Requirement already satisfied: six in /opt/anaconda3/envs/py37/lib/python3.7/site-packages (from absl-py>=0.4->tensorboard>=2.6.0->-r requirements.txt (line 16)) (1.16.0)\n",
      "Requirement already satisfied: munch in /opt/anaconda3/envs/py37/lib/python3.7/site-packages (from fiona>=1.8->geopandas>=0.8.1->-r requirements.txt (line 5)) (2.5.0)\n",
      "Requirement already satisfied: aiohttp in /opt/anaconda3/envs/py37/lib/python3.7/site-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.4.4->-r requirements.txt (line 14)) (3.7.4.post0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/anaconda3/envs/py37/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.6.0->-r requirements.txt (line 16)) (4.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/anaconda3/envs/py37/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.6.0->-r requirements.txt (line 16)) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/anaconda3/envs/py37/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.6.0->-r requirements.txt (line 16)) (4.7.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/anaconda3/envs/py37/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.6.0->-r requirements.txt (line 16)) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata in /opt/anaconda3/envs/py37/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard>=2.6.0->-r requirements.txt (line 16)) (4.7.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/anaconda3/envs/py37/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.6.0->-r requirements.txt (line 16)) (0.4.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/anaconda3/envs/py37/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard>=2.6.0->-r requirements.txt (line 16)) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/anaconda3/envs/py37/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard>=2.6.0->-r requirements.txt (line 16)) (1.26.6)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/envs/py37/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard>=2.6.0->-r requirements.txt (line 16)) (3.2)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/anaconda3/envs/py37/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.6.0->-r requirements.txt (line 16)) (3.1.1)\n",
      "Requirement already satisfied: chardet<5.0,>=2.0 in /opt/anaconda3/envs/py37/lib/python3.7/site-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.4.4->-r requirements.txt (line 14)) (4.0.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/anaconda3/envs/py37/lib/python3.7/site-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.4.4->-r requirements.txt (line 14)) (1.6.3)\n",
      "Requirement already satisfied: async-timeout<4.0,>=3.0 in /opt/anaconda3/envs/py37/lib/python3.7/site-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.4.4->-r requirements.txt (line 14)) (3.0.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/envs/py37/lib/python3.7/site-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.4.4->-r requirements.txt (line 14)) (5.1.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/anaconda3/envs/py37/lib/python3.7/site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard>=2.6.0->-r requirements.txt (line 16)) (3.5.0)\n",
      "Installing collected packages: typing-extensions, torch, numpy, fonttools, tensorboard, shapely, pandas, matplotlib, torchvision, rasterio, pytorch-lightning, POT, geopandas\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing-extensions 3.10.0.0\n",
      "    Uninstalling typing-extensions-3.10.0.0:\n",
      "      Successfully uninstalled typing-extensions-3.10.0.0\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.9.0\n",
      "    Uninstalling torch-1.9.0:\n",
      "      Successfully uninstalled torch-1.9.0\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.20.0\n",
      "    Uninstalling numpy-1.20.0:\n",
      "      Successfully uninstalled numpy-1.20.0\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 1.14.0\n",
      "    Uninstalling tensorboard-1.14.0:\n",
      "      Successfully uninstalled tensorboard-1.14.0\n",
      "  Attempting uninstall: shapely\n",
      "    Found existing installation: Shapely 1.7.1\n",
      "    Uninstalling Shapely-1.7.1:\n",
      "      Successfully uninstalled Shapely-1.7.1\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 1.1.5\n",
      "    Uninstalling pandas-1.1.5:\n",
      "      Successfully uninstalled pandas-1.1.5\n",
      "  Attempting uninstall: matplotlib\n",
      "    Found existing installation: matplotlib 3.3.4\n",
      "    Uninstalling matplotlib-3.3.4:\n",
      "      Successfully uninstalled matplotlib-3.3.4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.10.0\n",
      "    Uninstalling torchvision-0.10.0:\n",
      "      Successfully uninstalled torchvision-0.10.0\n",
      "  Attempting uninstall: rasterio\n",
      "    Found existing installation: rasterio 1.1.8\n",
      "    Uninstalling rasterio-1.1.8:\n",
      "      Successfully uninstalled rasterio-1.1.8\n",
      "  Attempting uninstall: pytorch-lightning\n",
      "    Found existing installation: pytorch-lightning 1.4.4\n",
      "    Uninstalling pytorch-lightning-1.4.4:\n",
      "      Successfully uninstalled pytorch-lightning-1.4.4\n",
      "  Attempting uninstall: POT\n",
      "    Found existing installation: POT 0.8.0\n",
      "    Uninstalling POT-0.8.0:\n",
      "      Successfully uninstalled POT-0.8.0\n",
      "  Attempting uninstall: geopandas\n",
      "    Found existing installation: geopandas 0.8.2\n",
      "    Uninstalling geopandas-0.8.2:\n",
      "      Successfully uninstalled geopandas-0.8.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow 1.14.0 requires tensorboard<1.15.0,>=1.14.0, but you have tensorboard 2.8.0 which is incompatible.\u001b[0m\n",
      "Successfully installed POT-0.8.1.0 fonttools-4.32.0 geopandas-0.10.2 matplotlib-3.5.1 numpy-1.21.6 pandas-1.3.5 pytorch-lightning-1.6.1 rasterio-1.2.10 shapely-1.8.1.post1 tensorboard-2.8.0 torch-1.11.0 torchvision-0.12.0 typing-extensions-4.1.1\n"
     ]
    }
   ],
   "source": [
    "!pip install -Ur requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import rasterio\n",
    "from rasterio.plot import reshape_as_image\n",
    "import PIL\n",
    "PIL.Image.MAX_IMAGE_PIXELS = None\n",
    "from PIL import Image\n",
    "import sys\n",
    "package = os.path.dirname(os.getcwd())\n",
    "sys.path.append(package)\n",
    "sys.path.append(package + 'utils')\n",
    "\n",
    "#import seaborn as sns\n",
    "#colors = sns.color_palette('tab10')\n",
    "#mypalette={'NN':colors[0], 'GMN':colors[4], 'OT':colors[1], 'OT on GPS position':colors[1], 'GW':colors[2], 'OT on GPS position + Tree species':colors[3]}\n",
    "#import matplotlib.pylab as plt\n",
    "#import tensorflow\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from utils.extract_features import *\n",
    "from utils.deepforest_detection import *\n",
    "#from utils.visualisation import *\n",
    "#from utils.plot_folium import *\n",
    "#from utils.plot_density import *\n",
    "#from utils.mapping import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🛸 Split raw drone RGB orthomosaics into image tiles\n",
    "1. **Extract drone informations on each site:**\n",
    "Based on the raw data we create the dataframe _ortho_data.csv_ that contains all important information on the drone orthomosaics RGB: minimimal and maximal latititude, longitude, width and height (pixels).\n",
    "\n",
    "\n",
    "2. **Split the orthomosaics into 400x400 tiles:**\n",
    "To be able to handle the drone data we need to split the large .tif files into tiles that is stored in _data/tiles_. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "directory = \"data/wwf_ecuador/RGB Orthomosaics\"\n",
    "save_dir = \"data/tiles\"\n",
    "\n",
    "# Extracting the main information for each site \n",
    "ortho_data = create_ortho_data(directory, os.path.join(save_dir, 'ortho_data.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Split images into tiles (might takes some minutes)\n",
    "for file in os.listdir(directory):\n",
    "    if file.endswith('.tif'):\n",
    "        # Open image file for reading (binary mode)\n",
    "        path_to_raster = os.path.join(directory, file)\n",
    "        name = file.replace('.tif', '')\n",
    "\n",
    "        tiles_dir = os.path.join(save_dir, name)\n",
    "        if not os.path.exists(tiles_dir):\n",
    "            os.makedirs(tiles_dir)        \n",
    "            split_raster(path_to_raster, base_dir=tiles_dir, patch_size=4000, patch_overlap=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🌴 Rescale drone bounds using field data\n",
    "\n",
    "The \"_field_data.csv_\" contains all the trees on the sites. Each row includes information on the tree parameters as well as the locations and calculated aboveground biomass (AGB) and carbon. \n",
    "\n",
    "PS: It is worth noting that the column \"updated diameter\" is being used for DBH. For completeness and transparancy, the comlumn \"diameter\" is kept and for the trees with missing values (especially cacao) an extrapolated diameter was calculated based on avg. diameter for that species for the year the tree was planted. \n",
    "\n",
    "A separate tutorial on how the processing of the field data is TBD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>diameter</th>\n",
       "      <th>height</th>\n",
       "      <th>year</th>\n",
       "      <th>plot_id</th>\n",
       "      <th>site</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>updated diameter</th>\n",
       "      <th>group</th>\n",
       "      <th>AGB</th>\n",
       "      <th>carbon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cacao</td>\n",
       "      <td>-2.181226</td>\n",
       "      <td>-79.576630</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>P8</td>\n",
       "      <td>Nestor Macias RGB</td>\n",
       "      <td>2761.628615</td>\n",
       "      <td>6831.070678</td>\n",
       "      <td>6.843647</td>\n",
       "      <td>cacao</td>\n",
       "      <td>5.444228</td>\n",
       "      <td>2.123249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cacao</td>\n",
       "      <td>-2.181312</td>\n",
       "      <td>-79.576412</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>P8</td>\n",
       "      <td>Nestor Macias RGB</td>\n",
       "      <td>5067.141765</td>\n",
       "      <td>7729.961820</td>\n",
       "      <td>6.843647</td>\n",
       "      <td>cacao</td>\n",
       "      <td>5.444228</td>\n",
       "      <td>2.123249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cacao</td>\n",
       "      <td>-2.181438</td>\n",
       "      <td>-79.576322</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>P8</td>\n",
       "      <td>Nestor Macias RGB</td>\n",
       "      <td>6025.223497</td>\n",
       "      <td>9026.909643</td>\n",
       "      <td>6.843647</td>\n",
       "      <td>cacao</td>\n",
       "      <td>5.444228</td>\n",
       "      <td>2.123249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cacao</td>\n",
       "      <td>-2.181593</td>\n",
       "      <td>-79.576154</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>P8</td>\n",
       "      <td>Nestor Macias RGB</td>\n",
       "      <td>7803.490078</td>\n",
       "      <td>10637.681956</td>\n",
       "      <td>6.843647</td>\n",
       "      <td>cacao</td>\n",
       "      <td>5.444228</td>\n",
       "      <td>2.123249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cacao</td>\n",
       "      <td>-2.181498</td>\n",
       "      <td>-79.576179</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>P8</td>\n",
       "      <td>Nestor Macias RGB</td>\n",
       "      <td>7531.400369</td>\n",
       "      <td>9648.963864</td>\n",
       "      <td>6.843647</td>\n",
       "      <td>cacao</td>\n",
       "      <td>5.444228</td>\n",
       "      <td>2.123249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4658</th>\n",
       "      <td>Musacea</td>\n",
       "      <td>-1.129593</td>\n",
       "      <td>-79.594408</td>\n",
       "      <td>23.236567</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>P7</td>\n",
       "      <td>Manuel Macias RGB</td>\n",
       "      <td>5481.100278</td>\n",
       "      <td>6416.246583</td>\n",
       "      <td>23.236567</td>\n",
       "      <td>banana</td>\n",
       "      <td>24.381901</td>\n",
       "      <td>9.508941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4659</th>\n",
       "      <td>Cacao</td>\n",
       "      <td>-1.129664</td>\n",
       "      <td>-79.594279</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>P7</td>\n",
       "      <td>Manuel Macias RGB</td>\n",
       "      <td>6767.025955</td>\n",
       "      <td>7172.157045</td>\n",
       "      <td>2.387319</td>\n",
       "      <td>cacao</td>\n",
       "      <td>0.676596</td>\n",
       "      <td>0.263872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4660</th>\n",
       "      <td>Musacea</td>\n",
       "      <td>-1.129678</td>\n",
       "      <td>-79.594442</td>\n",
       "      <td>21.645022</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>P7</td>\n",
       "      <td>Manuel Macias RGB</td>\n",
       "      <td>5147.097504</td>\n",
       "      <td>7321.370785</td>\n",
       "      <td>21.645022</td>\n",
       "      <td>banana</td>\n",
       "      <td>20.962055</td>\n",
       "      <td>8.175201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4661</th>\n",
       "      <td>Cacao</td>\n",
       "      <td>-1.129588</td>\n",
       "      <td>-79.594546</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>P7</td>\n",
       "      <td>Manuel Macias RGB</td>\n",
       "      <td>4102.201665</td>\n",
       "      <td>6366.720321</td>\n",
       "      <td>2.387319</td>\n",
       "      <td>cacao</td>\n",
       "      <td>0.676596</td>\n",
       "      <td>0.263872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4662</th>\n",
       "      <td>Cacao</td>\n",
       "      <td>-1.129495</td>\n",
       "      <td>-79.594575</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>P7</td>\n",
       "      <td>Manuel Macias RGB</td>\n",
       "      <td>3816.384864</td>\n",
       "      <td>5385.084392</td>\n",
       "      <td>2.387319</td>\n",
       "      <td>cacao</td>\n",
       "      <td>0.676596</td>\n",
       "      <td>0.263872</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4663 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         name       lat        lon   diameter  height    year plot_id  \\\n",
       "0       Cacao -2.181226 -79.576630   0.000000     0.0  2016.0      P8   \n",
       "1       Cacao -2.181312 -79.576412   0.000000     0.0  2016.0      P8   \n",
       "2       Cacao -2.181438 -79.576322   0.000000     0.0  2016.0      P8   \n",
       "3       Cacao -2.181593 -79.576154   0.000000     0.0  2016.0      P8   \n",
       "4       Cacao -2.181498 -79.576179   0.000000     0.0  2016.0      P8   \n",
       "...       ...       ...        ...        ...     ...     ...     ...   \n",
       "4658  Musacea -1.129593 -79.594408  23.236567     0.0  2019.0      P7   \n",
       "4659    Cacao -1.129664 -79.594279   0.000000     0.0  2019.0      P7   \n",
       "4660  Musacea -1.129678 -79.594442  21.645022     0.0  2019.0      P7   \n",
       "4661    Cacao -1.129588 -79.594546   0.000000     0.0  2019.0      P7   \n",
       "4662    Cacao -1.129495 -79.594575   0.000000     0.0  2019.0      P7   \n",
       "\n",
       "                   site            X             Y  updated diameter   group  \\\n",
       "0     Nestor Macias RGB  2761.628615   6831.070678          6.843647   cacao   \n",
       "1     Nestor Macias RGB  5067.141765   7729.961820          6.843647   cacao   \n",
       "2     Nestor Macias RGB  6025.223497   9026.909643          6.843647   cacao   \n",
       "3     Nestor Macias RGB  7803.490078  10637.681956          6.843647   cacao   \n",
       "4     Nestor Macias RGB  7531.400369   9648.963864          6.843647   cacao   \n",
       "...                 ...          ...           ...               ...     ...   \n",
       "4658  Manuel Macias RGB  5481.100278   6416.246583         23.236567  banana   \n",
       "4659  Manuel Macias RGB  6767.025955   7172.157045          2.387319   cacao   \n",
       "4660  Manuel Macias RGB  5147.097504   7321.370785         21.645022  banana   \n",
       "4661  Manuel Macias RGB  4102.201665   6366.720321          2.387319   cacao   \n",
       "4662  Manuel Macias RGB  3816.384864   5385.084392          2.387319   cacao   \n",
       "\n",
       "            AGB    carbon  \n",
       "0      5.444228  2.123249  \n",
       "1      5.444228  2.123249  \n",
       "2      5.444228  2.123249  \n",
       "3      5.444228  2.123249  \n",
       "4      5.444228  2.123249  \n",
       "...         ...       ...  \n",
       "4658  24.381901  9.508941  \n",
       "4659   0.676596  0.263872  \n",
       "4660  20.962055  8.175201  \n",
       "4661   0.676596  0.263872  \n",
       "4662   0.676596  0.263872  \n",
       "\n",
       "[4663 rows x 14 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "field_data = pd.read_csv('data/field_data.csv')\n",
    "field_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then to the actual rescaling\n",
    "list_sites = ['Carlos Vera Arteaga RGB', 'Carlos Vera Guevara RGB', 'Flora Pluas RGB', 'Leonor Aspiazu RGB', \n",
    "             'Manuel Macias RGB', 'Nestor Macias RGB']\n",
    "\n",
    "ortho_data = rescale_bounds(ortho_data, field_data, list_sites)\n",
    "ortho_data.to_csv(os.path.join(save_dir, 'ortho_data.csv'), index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔲 DeepForest Tree Detection\n",
    "\n",
    "From tiles to bounding box annotations! For that we use a pretrained and finetuned DeepForest model.\n",
    "\n",
    "Note reg finetuning: To make sure our model was able to detect the trees in these sites accurately, we finetuned it on some hand-created bounding boxes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading config file: /opt/anaconda3/envs/py37/lib/python3.7/site-packages/deepforest/data/deepforest_config.yml\n",
      "Loading saved model\n",
      "WARNING:tensorflow:From /opt/anaconda3/envs/py37/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-16 23:20:22.503349: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/anaconda3/envs/py37/lib/python3.7/site-packages/deepforest/keras_retinanet/backend/tensorflow_backend.py:104: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /opt/anaconda3/envs/py37/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "tracking <tf.Variable 'Variable:0' shape=(9, 4) dtype=float32> anchors\n",
      "tracking <tf.Variable 'Variable_1:0' shape=(9, 4) dtype=float32> anchors\n",
      "tracking <tf.Variable 'Variable_2:0' shape=(9, 4) dtype=float32> anchors\n",
      "tracking <tf.Variable 'Variable_3:0' shape=(9, 4) dtype=float32> anchors\n",
      "tracking <tf.Variable 'Variable_4:0' shape=(9, 4) dtype=float32> anchors\n"
     ]
    }
   ],
   "source": [
    "# Load model \n",
    "\n",
    "model = deepforest.deepforest(saved_model = os.getcwd()+'/data/model/deepforest/final_model_4000_epochs_35.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepForest annotations are saved for site Carlos Vera Arteaga RGB\n",
      "DeepForest annotations are saved for site Carlos Vera Guevara RGB\n",
      "DeepForest annotations are saved for site Leonor Aspiazu RGB\n",
      "DeepForest annotations are saved for site Flora Pluas RGB\n",
      "DeepForest annotations are saved for site Nestor Macias RGB\n",
      "DeepForest annotations are saved for site Manuel Macias RGB\n"
     ]
    }
   ],
   "source": [
    "# Detect trees per tile and return bounding box annotations for each site\n",
    "column_names = ['img_path', 'xmin', 'ymin', 'xmax', 'ymax', 'score']\n",
    "\n",
    "dir = os.path.join(os.getcwd(), 'data')\n",
    "tiles_dir = os.path.join(dir,'tiles')\n",
    "ann_dir = os.path.join(dir,'annotations')\n",
    "\n",
    "if not os.path.exists(ann_dir):\n",
    "    os.makedirs(ann_dir)\n",
    "\n",
    "for folder in os.listdir(tiles_dir):\n",
    "    if not (folder.startswith('.') or folder.startswith('ortho_data.csv')):\n",
    "        file_path = ann_dir + '/{}_annotations.csv'.format(folder)\n",
    "        if not os.path.exists(file_path):\n",
    "            annotations_files = pd.DataFrame(columns = column_names)\n",
    "            folder_path = os.path.join(tiles_dir,folder)\n",
    "            \n",
    "            for file in os.listdir(folder_path):\n",
    "                if not file.startswith('.'):\n",
    "                    tile_annotations = get_annotations(os.path.join(folder_path, file), model)\n",
    "                    annotations_files = pd.concat([annotations_files, tile_annotations])\n",
    "            annotations_files = annotations_files.reset_index(drop=True)\n",
    "\n",
    "            annotations_files.to_csv(file_path, index=False)\n",
    "        print('DeepForest annotations are saved for site {}'.format(folder))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Additional tile information per bounding box annotation\n",
    "\n",
    "For each tree annotation we add tree location, tile position, and site."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added info for Carlos Vera Arteaga RGB\n",
      "Added info for Carlos Vera Guevara RGB\n",
      "Added info for Flora Pluas RGB\n",
      "Added info for Leonor Aspiazu RGB\n",
      "Added info for Manuel Macias RGB\n",
      "Added info for Nestor Macias RGB\n"
     ]
    }
   ],
   "source": [
    "for site_name in list_sites:\n",
    "    for file in os.listdir(ann_dir):\n",
    "        if (file == '{}_annotations.csv'.format(site_name)):\n",
    "            file_path = os.path.join(ann_dir,file)\n",
    "            df = pd.read_csv(file_path)\n",
    "            \n",
    "            if not ('Xmin' in df.columns): # in case you have done this before\n",
    "                df['img_name'], df['tile_index'], df['tile_xmin'], df['tile_ymin'], df['tile_xmax'], df['tile_ymax'] = zip(*df['img_path'].map(expand_tile_features))\n",
    "                df[['x', 'y']] = df.apply(lambda x: [get_center(x.xmin,x.xmax), get_center(x.ymin,x.ymax)], axis=1, result_type=\"expand\")\n",
    "\n",
    "                df['Xmin'] = df.xmin + df.tile_xmin\n",
    "                df['Ymin'] = df.ymin + df.tile_ymin\n",
    "                df['Xmax'] = df.xmax + df.tile_xmin\n",
    "                df['Ymax'] = df.ymax + df.tile_ymin\n",
    "                df['X'] = df.x + df.tile_xmin\n",
    "                df['Y'] = df.y + df.tile_ymin\n",
    "\n",
    "                df[['lon', 'lat']] = df.apply(lambda x: convert_xy_tile_to_lonlat(x.img_name, x.tile_xmin, x.tile_ymin, x.x, x.y, ortho_data), axis=1, result_type=\"expand\")\n",
    "                df.to_csv(file_path, index = False)\n",
    "            print('Added info for {}'.format(site_name))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge annotations files of each site into one file\n",
    "all_annotations = pd.DataFrame()\n",
    "\n",
    "for file in os.listdir(ann_dir):\n",
    "    if not (file.startswith('.') or file.startswith('c') or file.startswith('a')):\n",
    "        file_path = os.path.join(ann_dir, file)\n",
    "        df = pd.read_csv(file_path)\n",
    "        all_annotations = pd.concat([all_annotations, df])\n",
    "all_annotations.to_csv(os.path.join(ann_dir,'all_annotations.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🍌 Cleaned bounding boxes\n",
    "As part of our work, we have manually cleaned the bounding boxes coming out of deepforest. This was done in two parts; one filtering out bboxes that were not of trees, due to size (e.g. too large area or only of a leaf) or due to wrong detection (of a car or grass). The second part consisted of labelling the trees as either \"banana\" (easily recognizable looking like a palm tree) or \"other\". \n",
    "\n",
    "Please find the cleaned dataset in \"_data/annotations/cleaned_\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['img_path', 'xmin', 'ymin', 'xmax', 'ymax', 'score', 'img_name',\n",
       "       'tile_index', 'tile_xmin', 'tile_ymin', 'tile_xmax', 'tile_ymax', 'x',\n",
       "       'y', 'Xmin', 'Ymin', 'Xmax', 'Ymax', 'X', 'Y', 'lon', 'lat',\n",
       "       'is_banana'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_annotations = pd.read_csv('data/annotations/cleaned/clean_annotations.csv')\n",
    "clean_annotations.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ↔️ Matching of tree label + bounding box\n",
    "\n",
    "TBD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
